{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_excel(\"./data/time_series_375_prerpocess_en.xlsx\").fillna(method='ffill')\n",
    "test = pd.read_excel(\"./data/time_series_test_110_preprocess_en.xlsx\").fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PATIENT_ID</th>\n",
       "      <th>RE_DATE</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>Admission time</th>\n",
       "      <th>Discharge time</th>\n",
       "      <th>outcome</th>\n",
       "      <th>Hypersensitive cardiac troponinI</th>\n",
       "      <th>hemoglobin</th>\n",
       "      <th>Serum chloride</th>\n",
       "      <th>...</th>\n",
       "      <th>mean corpuscular hemoglobin</th>\n",
       "      <th>Activation of partial thromboplastin time</th>\n",
       "      <th>High sensitivity C-reactive protein</th>\n",
       "      <th>HIV antibody quantification</th>\n",
       "      <th>serum sodium</th>\n",
       "      <th>thrombocytocrit</th>\n",
       "      <th>ESR</th>\n",
       "      <th>glutamic-pyruvic transaminase</th>\n",
       "      <th>eGFR</th>\n",
       "      <th>creatinine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-01-31 01:09:00</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-30 22:12:47</td>\n",
       "      <td>2020-02-17 12:40:09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-01-31 01:25:00</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-30 22:12:47</td>\n",
       "      <td>2020-02-17 12:40:09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>31.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-01-31 01:44:00</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-30 22:12:47</td>\n",
       "      <td>2020-02-17 12:40:09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136.0</td>\n",
       "      <td>103.1</td>\n",
       "      <td>...</td>\n",
       "      <td>31.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137.7</td>\n",
       "      <td>0.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>46.6</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-01-31 01:45:00</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-30 22:12:47</td>\n",
       "      <td>2020-02-17 12:40:09</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136.0</td>\n",
       "      <td>103.1</td>\n",
       "      <td>...</td>\n",
       "      <td>31.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137.7</td>\n",
       "      <td>0.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>46.6</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-01-31 01:56:00</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-30 22:12:47</td>\n",
       "      <td>2020-02-17 12:40:09</td>\n",
       "      <td>0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>136.0</td>\n",
       "      <td>103.1</td>\n",
       "      <td>...</td>\n",
       "      <td>31.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>137.7</td>\n",
       "      <td>0.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.0</td>\n",
       "      <td>46.6</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PATIENT_ID             RE_DATE  age  gender      Admission time  \\\n",
       "0         1.0 2020-01-31 01:09:00   73       1 2020-01-30 22:12:47   \n",
       "1         1.0 2020-01-31 01:25:00   73       1 2020-01-30 22:12:47   \n",
       "2         1.0 2020-01-31 01:44:00   73       1 2020-01-30 22:12:47   \n",
       "3         1.0 2020-01-31 01:45:00   73       1 2020-01-30 22:12:47   \n",
       "4         1.0 2020-01-31 01:56:00   73       1 2020-01-30 22:12:47   \n",
       "\n",
       "       Discharge time  outcome  Hypersensitive cardiac troponinI  hemoglobin  \\\n",
       "0 2020-02-17 12:40:09        0                               NaN         NaN   \n",
       "1 2020-02-17 12:40:09        0                               NaN       136.0   \n",
       "2 2020-02-17 12:40:09        0                               NaN       136.0   \n",
       "3 2020-02-17 12:40:09        0                               NaN       136.0   \n",
       "4 2020-02-17 12:40:09        0                              19.9       136.0   \n",
       "\n",
       "   Serum chloride  ...  mean corpuscular hemoglobin   \\\n",
       "0             NaN  ...                           NaN   \n",
       "1             NaN  ...                          31.9   \n",
       "2           103.1  ...                          31.9   \n",
       "3           103.1  ...                          31.9   \n",
       "4           103.1  ...                          31.9   \n",
       "\n",
       "   Activation of partial thromboplastin time  \\\n",
       "0                                        NaN   \n",
       "1                                        NaN   \n",
       "2                                        NaN   \n",
       "3                                        NaN   \n",
       "4                                        NaN   \n",
       "\n",
       "   High sensitivity C-reactive protein  HIV antibody quantification  \\\n",
       "0                                  NaN                          NaN   \n",
       "1                                  NaN                          NaN   \n",
       "2                                 43.1                          NaN   \n",
       "3                                 43.1                          NaN   \n",
       "4                                 43.1                          NaN   \n",
       "\n",
       "   serum sodium  thrombocytocrit  ESR  glutamic-pyruvic transaminase  eGFR  \\\n",
       "0           NaN              NaN  NaN                            NaN   NaN   \n",
       "1           NaN             0.12  NaN                            NaN   NaN   \n",
       "2         137.7             0.12  NaN                           16.0  46.6   \n",
       "3         137.7             0.12  NaN                           16.0  46.6   \n",
       "4         137.7             0.12  NaN                           16.0  46.6   \n",
       "\n",
       "   creatinine  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2       130.0  \n",
       "3       130.0  \n",
       "4       130.0  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model i kod\n",
    "dostępny na https://github.com/HAIRLAB/Pre_Surv_COVID_19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "\n",
    "import utils\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils_features_selection import *\n",
    "\n",
    "from xgboost import plot_tree\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "read_excel() got an unexpected keyword argument 'encoding'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2af536c5cb40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;31m## 特征筛选\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m     \u001b[0mselected_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m     \u001b[0msingle_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;31m## Compare Method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-2af536c5cb40>\u001b[0m in \u001b[0;36mfeatures_selection\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfeatures_selection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m## 读取375的数据\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mX_data_all_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_read_and_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;31m# name_dict = {'乳酸脱氢酶':'Lactate dehydrogenase (LDH)','淋巴细胞(%)':'Lymphocytes(%)','超敏C反应蛋白':'High-sensitivity C-reactive protein (hs-CRP)',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#          '钠':'Sodium','氯':'Chlorine','国际标准化比值':'International Normalized Ratio (INR)','嗜酸细胞(#)':'Eosinophils(#)',\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/studia/wb2/2021L-WB-ML/DeepJajo/utils_features_selection.py\u001b[0m in \u001b[0;36mdata_read_and_split\u001b[0;34m(is_dropna, sub_cols)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdata_read_and_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_dropna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msub_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;31m# data_df_unna为375数据集，data_pre_df为110数据集\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0mdata_df_unna\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata_pre_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_dropna\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mdata_df_unna\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_df_unna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msub_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'any'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/studia/wb2/2021L-WB-ML/DeepJajo/utils_features_selection.py\u001b[0m in \u001b[0;36mdata_preprocess\u001b[0;34m()\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdata_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mpath_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./data/time_series_375_prerpocess.xlsx'\u001b[0m  \u001b[0;31m# to_ml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     \u001b[0mdata_df_unna\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;31m# data_pre_df = pd.read_csv('./data/sample29_v3.csv',encoding='gbk')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/studia/wb2/2021L-WB-ML/DeepJajo/utils_features_selection.py\u001b[0m in \u001b[0;36mread_train_data\u001b[0;34m(path_train)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;31m###############################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0mdata_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gbk'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# train_sample_375_v2 train_sample_351_v4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m     \u001b[0mdata_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'PATIENT_ID'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# data_df = data_df.iloc[:,1:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m                 )\n\u001b[1;32m    295\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: read_excel() got an unexpected keyword argument 'encoding'"
     ]
    }
   ],
   "source": [
    "def features_selection():\n",
    "    ## 读取375的数据\n",
    "    X_data_all_features,Y_data,x_col = data_read_and_split()\n",
    "    # name_dict = {'乳酸脱氢酶':'Lactate dehydrogenase (LDH)','淋巴细胞(%)':'Lymphocytes(%)','超敏C反应蛋白':'High-sensitivity C-reactive protein (hs-CRP)',\n",
    "    #          '钠':'Sodium','氯':'Chlorine','国际标准化比值':'International Normalized Ratio (INR)','嗜酸细胞(#)':'Eosinophils(#)',\n",
    "    #          '嗜酸细胞(%)':'Eosinophils(%)','单核细胞(%)':'Monocytes(%)','白蛋白':'Albumin'}\n",
    "    #\n",
    "    # 构建一个dataframe用于存储特征的重要程度信息\n",
    "    import_feature = pd.DataFrame()\n",
    "    import_feature['col'] = x_col\n",
    "    import_feature['xgb'] = 0\n",
    "    # 重复100次试验\n",
    "    for i in range(100): # 50,150\n",
    "        #每次试验将375数据随机划分0.7训练集和0.3测试集，注意随机random_state=i\n",
    "        ## 注明：此方法原因是由于可获得的样本量较少，为了产生不同的训练样本集，使得特征的重要度排序更为稳定，从而选择了这样一种方式。\n",
    "        ## 通过每次不同的随机种子产生不同的样本，从而达到一定程度上的抑制少量样本的异常对特征的重要度带来的影响。\n",
    "        x_train, x_test, y_train, y_test = train_test_split(X_data_all_features, Y_data, test_size=0.3, random_state=i)\n",
    "        #定义模型超参数\n",
    "        model = xgb.XGBClassifier(\n",
    "                max_depth=4\n",
    "                ,learning_rate=0.2\n",
    "                ,reg_lambda=1\n",
    "                ,n_estimators=150\n",
    "                ,subsample = 0.9\n",
    "                ,colsample_bytree = 0.9)\n",
    "        #模型拟合\n",
    "        model.fit(x_train, y_train)\n",
    "        #累加特征重要程度\n",
    "        import_feature['xgb'] = import_feature['xgb']+model.feature_importances_/100\n",
    "    # 按照特征重要程度，降序排列\n",
    "    import_feature = import_feature.sort_values(axis=0, ascending=False, by='xgb')\n",
    "    print('Top 10 features:')\n",
    "    print(import_feature.head(10))\n",
    "    # Sort feature importances from GBC model trained earlier\n",
    "    # 按照特征重要程度的位置信息\n",
    "    indices = np.argsort(import_feature['xgb'].values)[::-1]\n",
    "    #获取前10个重要的特征位置\n",
    "    Num_f = 10\n",
    "    indices = indices[:Num_f]\n",
    "    \n",
    "    # Visualise these with a barplot\n",
    "    # plt.subplots(dpi=400,figsize=(12, 10))\n",
    "    plt.subplots(figsize=(12, 10))\n",
    "    # g = sns.barplot(y=list(name_dict.values())[:Num_f], x = import_feature.iloc[:Num_f]['xgb'].values[indices], orient='h') #import_feature.iloc[:Num_f]['col'].values[indices]\n",
    "    g = sns.barplot(y=import_feature.iloc[:Num_f]['col'].values[indices], x = import_feature.iloc[:Num_f]['xgb'].values[indices], orient='h') #import_feature.iloc[:Num_f]['col'].values[indices]\n",
    "    g.set_xlabel(\"Relative importance\",fontsize=18)\n",
    "    g.set_ylabel(\"Features\",fontsize=18)\n",
    "    g.tick_params(labelsize=14)\n",
    "    sns.despine() \n",
    "    # plt.savefig('feature_importances_v3.png')\n",
    "    plt.show()\n",
    "    # g.set_title(\"The mean feature importance of XGB models\");\n",
    "    # 获取前10重要特征的重要性数值\n",
    "    import_feature_cols= import_feature['col'].values[:10]\n",
    "\n",
    "    # 画特征金字塔\n",
    "    num_i = 1\n",
    "    val_score_old = 0\n",
    "    val_score_new = 0\n",
    "    while val_score_new >= val_score_old:\n",
    "        val_score_old = val_score_new\n",
    "        # 按重要程度顺序取特种\n",
    "        x_col = import_feature_cols[:num_i]\n",
    "        print(x_col)\n",
    "        X_data = X_data_all_features[x_col]#.values\n",
    "        ## 交叉验证\n",
    "        print('5-Fold CV:')\n",
    "        acc_train, acc_val, acc_train_std, acc_val_std = StratifiedKFold_func_with_features_sel(X_data.values,Y_data.values)\n",
    "        print(\"Train AUC-score is %.4f ; Validation AUC-score is %.4f\" % (acc_train,acc_val))\n",
    "        print(\"Train AUC-score-std is %.4f ; Validation AUC-score-std is %.4f\" % (acc_train_std,acc_val_std))\n",
    "        val_score_new = acc_val\n",
    "        num_i += 1\n",
    "        \n",
    "    print('Selected features:',x_col[:-1])\n",
    "    \n",
    "    return list(x_col[:-1])\n",
    "\n",
    "def single_tree(cols=['乳酸脱氢酶','淋巴细胞(%)','超敏C反应蛋白']):\n",
    "    print('single_tree:\\n')\n",
    "    #获取375病人（data_df_unna） 和110病人（data_pre_df）数据\n",
    "    data_df_unna,data_pre_df = data_preprocess()\n",
    "    #去掉全空行，此时375总数目变成351\n",
    "    data_df_unna = data_df_unna.dropna(subset=cols,how='any')\n",
    "\n",
    "    cols.append('Type2')\n",
    "    #获取病人的结局标签\n",
    "    Tets_Y = data_pre_df.reset_index()[['PATIENT_ID','出院方式']].copy()\n",
    "    #修改dataframe的名字\n",
    "    Tets_Y = Tets_Y.rename(columns={'PATIENT_ID': 'ID', '出院方式': 'Y'})\n",
    "    # 获取110病人的标签数据\n",
    "    y_true = Tets_Y['Y'].values\n",
    "\n",
    "    x_col = cols[:-1]\n",
    "    y_col = cols[-1]\n",
    "    # 获取351病人的三特征数据\n",
    "    x_np = data_df_unna[x_col].values\n",
    "    # 获取351病人的标签数据\n",
    "    y_np = data_df_unna[y_col].values\n",
    "    # 获取110病人的三特征数据\n",
    "    x_test = data_pre_df[x_col].values\n",
    "    # 在351病人上划分训练集和验证集，此时110视为测试集\n",
    "    X_train, X_val, y_train, y_val = train_test_split(x_np, y_np, test_size=0.3, random_state=6)\n",
    "    #限定单树xgb模型\n",
    "    model = xgb.XGBClassifier(\n",
    "        max_depth=3,\n",
    "        n_estimators=1,\n",
    "    )\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    #训练集混淆矩阵\n",
    "    pred_train = model.predict(X_train)\n",
    "    show_confusion_matrix(y_train, pred_train)\n",
    "    print(classification_report(y_train, pred_train))\n",
    "\n",
    "    #验证集混淆矩阵\n",
    "    pred_val = model.predict(X_val)\n",
    "    show_confusion_matrix(y_val, pred_val)\n",
    "    print(classification_report(y_val, pred_val))\n",
    "    #测试集混淆矩阵\n",
    "    \n",
    "    pred_test = model.predict(x_test)\n",
    "    print('True test label:',y_true)\n",
    "    print('Predict test label:',pred_test.astype('int32'))\n",
    "    show_confusion_matrix(y_true, pred_test)\n",
    "    print(classification_report(y_true, pred_test))\n",
    "    \n",
    "    plt.figure(dpi=300,figsize=(8,6))\n",
    "    plot_tree(model)\n",
    "    plt.show()\n",
    "    \n",
    "    graph = xgb.to_graphviz(model)\n",
    "    graph.render(filename='single-tree.dot')\n",
    "    #单树可视化\n",
    "    #ceate_feature_map(cols[:-1])\n",
    "    #graph = xgb.to_graphviz(model, fmap='xgb.fmap', num_trees=0, **{'size': str(10)})\n",
    "    #graph.render(filename='single-tree.dot')\n",
    "\n",
    "def Compare_with_other_method(sub_cols=['乳酸脱氢酶','淋巴细胞(%)','超敏C反应蛋白']):\n",
    "    # 读取351数据集（从375中删除sub_cols全为空的样本得到）\n",
    "    x_np,y_np,x_col = data_read_and_split(is_dropna=True,sub_cols=sub_cols)\n",
    "\n",
    "    #为了si的图4说明问题。如果是5折，画不出SI 图4\n",
    "    X_train, X_val, y_train, y_val = train_test_split(x_np, y_np, test_size=0.3, random_state=6)\n",
    "\n",
    "    #定义全特征下的比对方法\n",
    "    xgb_n_clf = xgb.XGBClassifier(\n",
    "        max_depth=4\n",
    "        ,learning_rate=0.2\n",
    "        ,reg_lambda=1\n",
    "        ,n_estimators=150\n",
    "        ,subsample = 0.9\n",
    "        ,colsample_bytree = 0.9\n",
    "        ,random_state=0)\n",
    "    tree_clf = tree.DecisionTreeClassifier(random_state=0,max_depth=4) #random_state=0,之前没加\n",
    "    RF_clf1 = RandomForestClassifier(random_state=0,n_estimators=150,max_depth=4,)\n",
    "    LR_clf = linear_model.LogisticRegression(random_state=0,C=1,solver='lbfgs')\n",
    "    LR_reg_clf = linear_model.LogisticRegression(random_state=0,C=0.1, solver='lbfgs')\n",
    "    \n",
    "    fig = plt.figure(dpi=400,figsize=(16, 8))\n",
    "\n",
    "    Num_iter = 100\n",
    "    \n",
    "    i = 0\n",
    "    labels_names = []\n",
    "    Moodel_name = ['Multi-tree XGBoost with all features',\n",
    "                   'Decision tree with all features',\n",
    "                   'Random Forest with all features',\n",
    "                   'Logistic regression with all features with regularization parameter = 1 (by default)',\n",
    "                   'Logistic regression with all features with regularization parameter = 10',]\n",
    "    for model in [xgb_n_clf,tree_clf,RF_clf1,LR_clf,LR_reg_clf]:\n",
    "        print('Model:'+Moodel_name[i])\n",
    "        #以f1的评价方式来k折\n",
    "        acc_train, acc_val, acc_train_std, acc_val_std = StratifiedKFold_func(x_np.values, y_np.values,Num_iter,model, score_type ='f1')\n",
    "        #print('F1-score of Train:%.6f with std:%.4f \\nF1-score of Validation:%.4f with std:%.6f '%(acc_train,acc_train_std,acc_val,acc_val_std))\n",
    "        # 以auc的评价方式来k折\n",
    "        acc_train, acc_val, acc_train_std, acc_val_std = StratifiedKFold_func(x_np.values, y_np.values,Num_iter,model, score_type ='auc')\n",
    "        print('AUC of Train:%.6f with std:%.4f \\nAUC of Validation:%.6f with std:%.4f '%(acc_train,acc_train_std,acc_val,acc_val_std))\n",
    "\n",
    "        #为了画si图4\n",
    "        model.fit(X_train,y_train)\n",
    "        pred_train_probe = model.predict_proba(X_train)[:,1]\n",
    "        pred_val_probe = model.predict_proba(X_val)[:,1]\n",
    "        #plot_roc(y_val, pred_val_probe,Moodel_name[i],fig,labels_names,i) # 为了画si图4中的test\n",
    "        plot_roc(y_train, pred_train_probe,Moodel_name[i],fig,labels_names,i) # 为了画si图4 train\n",
    "        print('AUC socre:',roc_auc_score(y_val, pred_val_probe))\n",
    "        \n",
    "        i = i+1\n",
    "\n",
    "    ## 三特征的单树模型对比\n",
    "    x_np_sel = x_np[sub_cols] #选择三特征\n",
    "    ## 划分数据集是为了单树的单次训练并生成AUC图，划分方式和之前保存一致。\n",
    "    X_train, X_val, y_train, y_val = train_test_split(x_np_sel, y_np, test_size=0.3, random_state=6) \n",
    "\n",
    "    #为了三特征的模型对比\n",
    "    xgb_clf = xgb.XGBClassifier(\n",
    "        max_depth=3,\n",
    "        n_estimators=1,\n",
    "        random_state=0,\n",
    "    )\n",
    "    \n",
    "    tree_clf = tree.DecisionTreeClassifier(random_state=0,max_depth=3)\n",
    "    RF_clf2 = RandomForestClassifier(random_state=0,n_estimators=1,max_depth=3,)\n",
    "\n",
    "    #i = 0\n",
    "    Moodel_name = ['Single-tree XGBoost with three features',\n",
    "                   'Decision tree with three features',\n",
    "                   'Random Forest with a single tree constraint with three features',]\n",
    "    for model in [xgb_clf,tree_clf,RF_clf2]:\n",
    "        print('Model'+Moodel_name[i-5])\n",
    "        #f1的结果\n",
    "        acc_train, acc_val, acc_train_std, acc_val_std = StratifiedKFold_func(x_np_sel.values, y_np.values,Num_iter,model, score_type ='f1')\n",
    "        #print('F1-score of Train:%.6f with std:%.4f \\nF1-score of Validation:%.4f with std:%.6f '%(acc_train,acc_train_std,acc_val,acc_val_std))\n",
    "        #auc的结果\n",
    "        acc_train, acc_val, acc_train_std, acc_val_std = StratifiedKFold_func(x_np_sel.values, y_np.values,Num_iter,model, score_type ='auc')\n",
    "        print('AUC of Train:%.6f with std:%.4f \\nAUC of Validation:%.6f with std:%.4f '%(acc_train,acc_train_std,acc_val,acc_val_std))\n",
    "        \n",
    "        model.fit(X_train,y_train)\n",
    "        pred_train_probe = model.predict_proba(X_train)[:,1]    # 为了画si图4中的train\n",
    "        pred_val_probe = model.predict_proba(X_val)[:,1]    # 为了画si图4中的test\n",
    "        #plot_roc(y_val, pred_val_probe,Moodel_name[i-5],fig,labels_names,i) # 为了画si图4中的test\n",
    "        plot_roc(y_train, pred_train_probe,Moodel_name[i-5],fig,labels_names,i)# 为了画si图4中的train\n",
    "        print('AUC socre:',roc_auc_score(y_val, pred_val_probe))\n",
    "        \n",
    "        i = i+1\n",
    "    \n",
    "    plt.plot([0,1],[0,1],'r--')\n",
    "    plt.legend(loc='SouthEastOutside', fontsize=14)\n",
    "    plt.savefig('AUC_train.png')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    ## 特征筛选\n",
    "    selected_cols = features_selection()\n",
    "    single_tree()\n",
    "    ## Compare Method\n",
    "    print('Compare with other methods')    \n",
    "    Compare_with_other_method(selected_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
